## 9.1. I/O 端口和 I/O 内存

每个外围设备都通过写入和读取其寄存器来控制。大多数时候，设备有多个寄存器，并且在连续的地址上访问它们，或者在内存地址空间中，或者在 I/O 地址空间中。在硬件层面，内存区域和 I/O 区域之间没有概念上的区别：两者都是通过在地址总线和控制总线上断言电信号（即读和写信号） 并通过读取来访问它们来自或写入数据总线。
> 并非所有计算机平台都使用读和写信号；有些有不同的方式来寻址外部电路。然而，这种差异在软件级别上是无关紧要的，我们假设所有人都已阅读和编写以简化讨论。

虽然一些 CPU 制造商在其芯片中实现了单一地址空间，但其他制造商认为外围设备与内存不同，因此应该有一个单独的地址空间。某些处理器（最著名的是 x86 系列）具有用于 I/O 端口的单独读写电线以及用于访问端口的特殊 CPU 指令。

由于外围设备是为了适应外围总线而构建的，并且最流行的 I/O 总线是在个人计算机上建模的，因此即使没有单独的 I/O 端口地址空间的处理器也必须伪造读取和写入 I/O 端口当访问一些外围设备时，通常通过外部芯片组或CPU内核中的额外电路来实现。后一种解决方案在用于嵌入式用途的微型处理器中很常见。

出于同样的原因，Linux 在其运行的所有计算机平台上都实现了 I/O 端口的概念，甚至在 CPU 实现单个地址空间的平台上也是如此。端口访问的实现有时取决于主机的具体品牌和型号（因为不同型号使用不同的芯片组将总线事务映射到内存地址空间）。

即使外设总线具有用于 I/O 端口的单独地址空间，并非所有设备都将其寄存器映射到 I/O 端口。虽然 I/O 端口的使用对于 ISA 外围板来说很常见，但大多数 PCI 设备将寄存器映射到内存地址区域。这种 I/O 内存方法通常是首选，因为它不需要使用专用处理器指令；CPU 内核访问内存的效率要高得多，并且编译器在访问内存时在寄存器分配和寻址模式选择方面有更大的自由度。

### 9.1.1. I/O 寄存器和传统存储器
尽管硬件寄存器和内存之间非常相似，但访问 I/O 寄存器的程序员必须小心，避免被可以修改预期 I/O 行为的 CPU（或编译器）优化所欺骗。

I/O 寄存器和 RAM 之间的主要区别在于 I/O 操作有副作用，而内存操作没有副作用：内存写入的唯一作用是将值存储到某个位置，而内存读取则返回最后写入的值。由于内存访问速度对 CPU 性能至关重要，因此已通过多种方式对无副作用情况进行了优化：缓存值以及重新排序读/写指令。

编译器可以将数据值缓存到 CPU 寄存器中，而不会将其写入内存，即使存储它们，写入和读取操作也可以在缓存内存上进行操作，而无需到达物理 RAM。重新排序也可以发生在编译器级别和硬件级别：如果指令序列以与程序文本中出现的顺序不同的顺序运行，通常可以更快地执行指令序列，例如，为了防止程序中的互锁RISC 流水线。在 CISC 处理器上，需要大量时间的操作可以与其他更快的操作同时执行。

某些在常规内存操作中效果良好的优化，当应用于I/O操作时可能会引发问题，特别是在单处理器系统中。干扰与I/O操作相关的副作用可能对驱动程序和硬件访问的正确运行产生不利影响。在处理涉及I/O操作的代码时，需要谨慎考虑，可能需要采用不同的优化策略。处理器无法预见某些其他进程（在单独的处理器上运行，或 I/O 控制器内部发生的事情）依赖于内存访问顺序的情况。编译器或 CPU 可能只是试图智取您并重新排序您请求的操作；结果可能是非常难以调试的奇怪错误。因此，驱动程序必须确保在访问寄存器时不执行缓存并且不发生读或写重新排序。

硬件缓存的问题是最容易面临的：底层硬件已经配置（自动或通过 Linux 初始化代码）在访问 I/O 区域（无论是内存还是端口区域）时禁用任何硬件缓存。

编译器优化和硬件重新排序的解决方案是在必须按特定顺序对硬件（或另一个处理器）可见的操作之间放置内存屏障。Linux 提供了四个宏来满足所有可能的排序需求：
```c
#include <linux/kernel.h>
void barrier(void)
```
该函数告诉编译器插入内存屏障，但对硬件没有影响。编译后的代码将当前修改并驻留在 CPU 寄存器中的所有值存储到内存中，并在需要时重新读取它们。对屏障的调用可以防止跨屏障的编译器优化，但可以让硬件自由地进行自己的重新排序。

```c
#include <asm/system.h>
void rmb(void);
void read_barrier_depends(void);
void wmb(void);
void mb(void);
```
这些函数在编译的指令流中插入硬件内存屏障；它们的实际实例化取决于平台。当使用“rmb”（读内存屏障）时，它会确保在屏障之前出现的任何内存读操作在执行任何后续的内存读操作之前都已完成。这意味着它强制执行内存读操作的严格顺序，以防止数据竞争，并确保数据按正确的顺序读取。这在多线程或多处理器系统中特别重要，因为多个线程或处理器可能同时访问共享内存。使用“rmb”可以确保内存读操作以可预测和有序的方式进行，这对于维护数据一致性和防止并发程序中的意外行为至关重要。wmb 保证写操作的顺序，而 mb 指令则保证两者。这些函数中的每一个都是屏障的超集。

read_barrier_depends 是一种特殊的、较弱的读屏障形式。rmb 阻止跨屏障的所有读取重新排序，而 read_barrier_depends 仅阻止依赖于其他读取数据的读取重新排序。这种区别很微妙，并且并非在所有架构上都存在。除非您确切了解发生了什么，并且您有理由相信完全读取屏障会造成过高的性能成本，否则您可能应该坚持使用rmb.

```c
void smp_rmb(void);
void smp_read_barrier_depends(void);
void smp_wmb(void);
void smp_mb(void);
```
这些版本的屏障宏仅在为 SMP 系统编译内核时才插入硬件屏障；否则，它们都会扩展为简单的屏障调用。

设备驱动程序中内存屏障的典型用法可能具有以下形式：
```c
writel(dev->registers.addr, io_destination_address);
writel(dev->registers.size, io_size);
writel(dev->registers.operation, DEV_READ);
wmb(  );
writel(dev->registers.control, DEV_GO);
```
在这种情况下，重要的是要确保在告诉它开始之前控制特定操作的所有设备寄存器都已正确设置。内存屏障强制按必要的顺序完成写入。

由于内存屏障会影响性能，因此应仅在真正需要的地方使用它们。不同类型的屏障也可能具有不同的性能特征，因此值得使用尽可能具体的类型。例如，在x86架构上，wmb()当前不执行任何操作，因为处理器外部的写入不会被重新排序。然而，读取会被重新排序，因此 mb() 比 wmb() 慢。

值得注意的是，大多数其他处理同步的内核原语（例如自旋锁和atomic_t操作）也充当内存屏障。另外值得注意的是，一些外设总线（例如 PCI 总线）有其自身的缓存问题；我们将在后面的章节中讨论这些内容。

一些架构允许赋值和内存屏障的有效组合。内核提供了一些执行这种组合的宏；在默认情况下，它们定义如下：
```c
#define set_mb(var, value)  do {var = value; mb(  );}  while 0
#define set_wmb(var, value) do {var = value; wmb(  );} while 0
#define set_rmb(var, value) do {var = value; rmb(  );} while 0
```
在适当的情况下，asm/system.h 定义这些宏以使用特定于体系结构的指令来更快地完成任务。请注意，set_rmb 仅由少数架构定义。（使用 do...while 构造是标准 C 习惯用法，它使扩展宏在所有上下文中都像普通 C 语句一样工作。）

